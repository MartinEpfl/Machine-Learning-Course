{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"trainFile.csv\"#\"C:/Users/Martin/Desktop/Workspace/Machine_Learning/data/data/trainFile.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "def standardize(x):\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    return std_data\n",
    "tX = standardize(tX)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss_logisitic(y,tx,w):\n",
    "    \n",
    "    result = tx*(delta(tx@w) -y)\n",
    "    return result\n",
    "\n",
    "def compute_loss_regression(y,tx,w, lambda_):\n",
    "    return np.sum( np.log((1-y)/2 + y*delta(tx@w))) + (lambda_/2)*np.sum(w**2)\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    N = y.shape[0]\n",
    "    e = y - (tx @ w)\n",
    "    result = 1/(2*N) * (np.transpose(e) @ e)\n",
    "    return result\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    solution =  -(1/y.shape[0])*(np.transpose(tx) @ (y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    #Here N  =1\n",
    "    solution =  -(1/2)*(tx.T.dot(y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "def delta(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "          \n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    result = np.zeros((x.shape[0], x.shape[1]*(degree+1)))\n",
    "    \n",
    "    for i in range(degree+1):\n",
    "        result[:,x.shape[1]*i:x.shape[1]*(i+1)] = np.power(x,i)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919352495949218\n",
      "0.7930378408672416\n",
      "0.7939171148444344\n",
      "0.7945316279428924\n",
      "0.7949488277918012\n",
      "0.7952167459905002\n",
      "0.7953710073709819\n",
      "0.7954532259435158\n",
      "0.79549924840252\n",
      "0.7955376136127158\n",
      "0.795602287905121\n",
      "0.7957408652558436\n",
      "0.7959984495594488\n",
      "0.7963601294678077\n",
      "0.7967211304967513\n",
      "0.7969886542034713\n",
      "0.797152501813258\n",
      "0.7972476366227846\n",
      "0.797317395089821\n",
      "0.7974139309924346\n",
      "0.7976040615067156\n",
      "0.7979349828733509\n",
      "0.7984194727930435\n",
      "0.7991695739602255\n",
      "0.8004914160965029\n",
      "0.8027644185070709\n",
      "0.8066486890138312\n",
      "0.8136491222117739\n",
      "0.8255335294113024\n",
      "0.8421266231749194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xtPoly = build_poly(tX,3)\n",
    "lambdas = np.logspace(-10, 0, 30)\n",
    "for lambda_ in lambdas:\n",
    "    weights = ridge_regression(y, xtPoly, lambda_)\n",
    "    error = np.sqrt(2*compute_loss(y,xtPoly,weights))\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w -gamma*gradient\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    losses=[]\n",
    "    for n_iter in range(max_iters):\n",
    "        i = np.random.randint(y.shape[0])\n",
    "        gradient = compute_stoch_gradient(y[i],tx[i],w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares and solving equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    x = tx\n",
    "    gram = x.T @ x\n",
    "    if np.linalg.det(gram)!=0:\n",
    "        w = np.linalg.inv(gram)@x.T@y\n",
    "    else:\n",
    "        w = np.linalg.solve(gram,x.T@y)\n",
    "    return w, compute_loss(y,tx,w)\n",
    "## Least squares using Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    #Using L2\n",
    "    lambdaPrime = lambda_*(2*tx.shape[0])\n",
    "    x = tx\n",
    "    gramLambda = x.T@x + np.eye(x.shape[1])*lambdaPrime\n",
    "    w = np.linalg.solve(gramLambda,x.T@y)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_it in range(max_iters):\n",
    "        #loss = compute_loss_logisitic(y,tx,w)\n",
    "        i = np.random.randint(y.shape[0])\n",
    "       # gradient = compute_stoch_gradient(y[i],tx[i],w)\n",
    "        gradient = compute_loss_logisitic(y[i],tx[i],w)\n",
    "        w = w - gamma*gradient\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_,initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        i = np.random.randint(y.shape[0])\n",
    "        #gradient = compute_stoch_gradient(y[i],tx[i],w)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5250604082126434e+110\n",
      "[0.3991067428443696, 0.47682010075301834, 0.3889523149681917, 0.4361889210773641, 0.4791089398813712, 0.3988914575644723]\n",
      "DONE\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#Weight : Linear regression using gradient descent \n",
    "inital_w = np.zeros(30)\n",
    "loss = []\n",
    "weightGD, lossGD = least_squares_GD(y, tX, inital_w, 50, 0.1)\n",
    "loss.append(lossGD)\n",
    "weightSGD, lossSGD = least_squares_SGD(y, tX, inital_w, 50, 0.01)\n",
    "loss.append(lossSGD)\n",
    "weightLS, lossLS = least_squares(y, tX)\n",
    "loss.append(lossLS)\n",
    "#weightLSPol, lossLSPol = polynomial_regression(y, tX)\n",
    "#loss.append(lossLSPol)\n",
    "weightRR, lossRR = ridge_regression(y, tX, 1)\n",
    "loss.append(lossRR)\n",
    "\n",
    "weightsLR,_ = logistic_regression(y, tX, inital_w, 50, 0.001)\n",
    "loss.append(compute_loss(y,tX,weightsLR))\n",
    "\n",
    "\n",
    "weightsRLR,_ = reg_logistic_regression(y, tX, 1, inital_w, 50, 0.1)\n",
    "loss.append(compute_loss(y,tX,weightsRLR))\n",
    "print(loss)\n",
    "#plot(lossSGD)\n",
    "print(\"DONE\")\n",
    "print(\"DONE\")\n",
    "\n",
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weightSGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0abe1b4507f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweightSGD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weightSGD' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TEST_PATH = 'testFile.csv' # TODO: download train data and supply path here \n",
    "print(\"done\")\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "print(\"done\")\n",
    "\n",
    "y_pred = predict_labels(weightLS, tX_test)\n",
    "print(\"done\")\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
